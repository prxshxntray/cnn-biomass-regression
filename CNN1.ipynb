{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prxshxntray/cnn-biomass-regression/blob/main/CNN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "99d5cce3",
      "metadata": {
        "id": "99d5cce3",
        "outputId": "3a29053b-3f2c-4b43-9cd3-1a4112d5143f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cnn_workflow_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3410400424.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from cnn_workflow_utils import (\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mImageDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mTARGET_COLUMNS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cnn_workflow_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "print(torch.xpu.is_available())  # torch.xpu is the API for Intel GPU support\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms\n",
        "import pathlib\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "from cnn_workflow_utils import (\n",
        "    ImageDataset,\n",
        "    TARGET_COLUMNS,\n",
        "    build_model,\n",
        "    calculate_global_weighted_r2,\n",
        "    get_device,\n",
        "    train_regression,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages, take note that line 6 is specific to my Intel Core GPU, please change (and in subsequent code below) to suit your own GPU [Also downloading Pytorch on different GPU setups might be an issue since I assume most will be using Nvidea - of which I am not using ; so please amend ]"
      ],
      "metadata": {
        "id": "axvs_Q9YG7pC"
      },
      "id": "axvs_Q9YG7pC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADING DATA**"
      ],
      "metadata": {
        "id": "SioS9BRgHmSw"
      },
      "id": "SioS9BRgHmSw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b32d150",
      "metadata": {
        "id": "4b32d150"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have saved all of the datasets under ../data/ though I am not sure how this is replicated on google colab - need to check"
      ],
      "metadata": {
        "id": "lkicZlH8HN84"
      },
      "id": "lkicZlH8HN84"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d30bb518",
      "metadata": {
        "id": "d30bb518"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('../data/test.csv')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I loaded in the test dataset but I did not run my code on it fyi, incase you were wondering"
      ],
      "metadata": {
        "id": "nGOIwH6zHXQw"
      },
      "id": "nGOIwH6zHXQw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA MANIPULATION**"
      ],
      "metadata": {
        "id": "EbvE-E1nHtcM"
      },
      "id": "EbvE-E1nHtcM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3967cb",
      "metadata": {
        "id": "3b3967cb"
      },
      "outputs": [],
      "source": [
        "df_wide = df.copy()\n",
        "df_wide = df_wide.pivot(index = 'image_path', columns = 'target_name', values = 'target').reset_index()\n",
        "df_wide[\"cleaned_path\"] = df_wide[\"image_path\"].str.replace(r'^train[\\\\/]', '', regex=True)\n",
        "df_wide.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SET UP FOR CNN / FUNCTIONS FOR CNN**"
      ],
      "metadata": {
        "id": "QrGz-P5JHzgg"
      },
      "id": "QrGz-P5JHzgg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97fe5055",
      "metadata": {
        "id": "97fe5055"
      },
      "outputs": [],
      "source": [
        "image_folder = '../data/train'\n",
        "assert os.path.exists(image_folder), f\"Image folder {image_folder} does not exist.\"\n",
        "\n",
        "df_wide[\"full_path\"] = df_wide[\"cleaned_path\"].apply(\n",
        "    lambda fname: os.path.join(image_folder, fname)\n",
        ")\n",
        "\n",
        "df_wide.head(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This merges the picture directory to the excel table"
      ],
      "metadata": {
        "id": "5a4gsBbJH5rv"
      },
      "id": "5a4gsBbJH5rv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06aa8432",
      "metadata": {
        "id": "06aa8432"
      },
      "outputs": [],
      "source": [
        "image_folder_test = '../data/test'\n",
        "assert os.path.exists(image_folder_test), f\"Image folder {image_folder_test} does not exist.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random check"
      ],
      "metadata": {
        "id": "mYoi5pB2H_Dg"
      },
      "id": "mYoi5pB2H_Dg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06b773e",
      "metadata": {
        "id": "c06b773e"
      },
      "outputs": [],
      "source": [
        "test_path = \"../data/train\\\\ID1011485656.jpg\"\n",
        "print(\"Path:\", test_path)\n",
        "print(\"Exists?\", os.path.exists(test_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a1ecd6",
      "metadata": {
        "id": "b4a1ecd6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(df_wide, test_size=0.3, random_state=1)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test Val split"
      ],
      "metadata": {
        "id": "aJzZDAvsICVJ"
      },
      "id": "aJzZDAvsICVJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4ba806",
      "metadata": {
        "id": "0e4ba806"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),        # ← better than CenterCrop for training\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # ← adds variety\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),        # ← deterministic for val/test\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tranformation set up for the pictures; to be pre processed before feeding into CNN"
      ],
      "metadata": {
        "id": "4ULi2VHcIEsS"
      },
      "id": "4ULi2VHcIEsS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa4c581",
      "metadata": {
        "id": "daa4c581"
      },
      "outputs": [],
      "source": [
        "# ImageDataset is imported from cnn_workflow_utils.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Transform the excel table data and picture into meaningful Tensor"
      ],
      "metadata": {
        "id": "HeR1WuJKIKj2"
      },
      "id": "HeR1WuJKIKj2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01de05d8",
      "metadata": {
        "id": "01de05d8"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageDataset(train_df, transform = train_transform)\n",
        "val_dataset = ImageDataset(val_df, transform=eval_transform)\n",
        "test_dataset = ImageDataset(test_df, transform=eval_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58278552",
      "metadata": {
        "id": "58278552"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader for the CNN"
      ],
      "metadata": {
        "id": "DL5e5TI4IRy-"
      },
      "id": "DL5e5TI4IRy-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de67f27c",
      "metadata": {
        "id": "de67f27c"
      },
      "outputs": [],
      "source": [
        "# Get one batch\n",
        "for images, targets in train_loader:\n",
        "    print(\"Image batch shape:\", images.shape)      # Should be [batch_size, 3, 224, 224]\n",
        "    print(\"Target batch shape:\", targets.shape)   # Should be [batch_size, 5]\n",
        "    print(\"Image dtype:\", images.dtype)           # Should be torch.float32\n",
        "    print(\"Target sample:\", targets[0])           # Should be 5 numbers\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "ZsDN_EdgIVV2"
      },
      "id": "ZsDN_EdgIVV2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b6f2fcf",
      "metadata": {
        "id": "6b6f2fcf"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "\n",
        "weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
        "model = build_model(\"resnet18\", num_targets=5, weights=weights)\n",
        "\n",
        "# Swap architecture with 'densenet121' or 'efficientnet_b0' to experiment.\n",
        "device = get_device()\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT** - seting up the initial RESNET (need to downalod first, not sure how this is reflected in the collab though) Also in line 9, you will need to amend this for sure since it uses my Intel XPU GPU!"
      ],
      "metadata": {
        "id": "LW7APcnLIWgq"
      },
      "id": "LW7APcnLIWgq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0426e4",
      "metadata": {
        "id": "df0426e4"
      },
      "outputs": [],
      "source": [
        "# Freeze all parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze ONLY the final layer\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr = 0.001)\n",
        "# above only fine tunes the Final layer, bottom fine-tunes the entire network\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezes learning for all parameters except the last layer - since the first layer are the pre-trained RESNET.\n",
        "Used MSE as the Loss function\n",
        "Used Adam as the Optimisation function"
      ],
      "metadata": {
        "id": "kyzXB27tImoz"
      },
      "id": "kyzXB27tImoz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d37a12c",
      "metadata": {
        "id": "5d37a12c"
      },
      "outputs": [],
      "source": [
        "# # Get a sample batch\n",
        "# sample_images, sample_targets = next(iter(train_loader))\n",
        "# sample_images, sample_targets = sample_images.to(device), sample_targets.to(device)\n",
        "\n",
        "# # Forward pass\n",
        "# outputs = model(sample_images)\n",
        "# print(\"Model output shape:\", outputs.shape)  # Should be [batch_size, 5]\n",
        "# print(\"Sample prediction:\", outputs[0].detach().cpu().numpy())\n",
        "# print(\"Sample target:\", sample_targets[0].cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c393649",
      "metadata": {
        "id": "7c393649"
      },
      "outputs": [],
      "source": [
        "# train_regression is imported from cnn_workflow_utils.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for the regression model"
      ],
      "metadata": {
        "id": "U8kgw0YDIx8n"
      },
      "id": "U8kgw0YDIx8n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9cf5146",
      "metadata": {
        "id": "a9cf5146"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "train_losses, val_losses = train_regression(\n",
        "    model, num_epochs, train_loader, val_loader,\n",
        "    criterion, optimizer, device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "018564c5",
      "metadata": {
        "id": "018564c5"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"final_model.pth\")\n",
        "print(\"Model saved to final_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model parameters for easy replication in the future"
      ],
      "metadata": {
        "id": "rVLX-qwVI1mu"
      },
      "id": "rVLX-qwVI1mu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9f1b77",
      "metadata": {
        "id": "cd9f1b77"
      },
      "outputs": [],
      "source": [
        "# calculate_global_weighted_r2 is imported from cnn_workflow_utils.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to find the R^2 as detailed per the Kaggle page"
      ],
      "metadata": {
        "id": "coufS-6YI5aN"
      },
      "id": "coufS-6YI5aN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fff73a55",
      "metadata": {
        "id": "fff73a55"
      },
      "outputs": [],
      "source": [
        "# Recreate the model architecture\n",
        "model_eval = build_model(\"resnet18\", num_targets=5, weights=None)\n",
        "\n",
        "# Load weights\n",
        "model_eval.load_state_dict(torch.load(\"final_model.pth\", map_location=device))\n",
        "model_eval = model_eval.to(device)\n",
        "model_eval.eval()  # set to evaluation mode\n",
        "\n",
        "# Now evaluate on test set\n",
        "test_loss = 0.0\n",
        "all_preds = []      # ← collect all predictions\n",
        "all_targets = []    # ← collect all targets\n",
        "with torch.no_grad():\n",
        "    for images, targets in test_loader:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        preds = model_eval(images)\n",
        "        loss = criterion(preds, targets)\n",
        "        test_loss += loss.item()\n",
        "        all_preds.append(preds)\n",
        "        all_targets.append(targets)\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "print(f\"Test Loss (from saved model): {avg_test_loss:.6f}\")\n",
        "\n",
        "# Concatenate all batches into single tensors\n",
        "all_preds = torch.cat(all_preds, dim=0)      # [N_test, 5]\n",
        "all_targets = torch.cat(all_targets, dim=0)  # [N_test, 5]\n",
        "print(all_preds.shape, all_targets.shape)\n",
        "\n",
        "# Calculate globally weighted R²\n",
        "test_r2 = calculate_global_weighted_r2(all_preds, all_targets)\n",
        "print(f\"Test Weighted R²: {test_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First simple run thus far"
      ],
      "metadata": {
        "id": "aQadTv8ZI8pb"
      },
      "id": "aQadTv8ZI8pb"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/prxshxntray/cnn-biomass-regression.git"
      ],
      "metadata": {
        "id": "dncXXZu-LMtu"
      },
      "id": "dncXXZu-LMtu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-8HPjiOvLPHu"
      },
      "id": "-8HPjiOvLPHu"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv-MLDL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}